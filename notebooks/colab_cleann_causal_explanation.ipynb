{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEANN: Causal Lens for Explaining Attention Networks\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading attention matrices from transformer models\n",
    "2. Applying the **CLEANN** algorithm to extract causal graphs from attention patterns\n",
    "3. Generating minimal explanations for target tokens/features\n",
    "4. Visualizing learned causal structures and explanation sets\n",
    "\n",
    "**Paper**: [CLEANN](https://arxiv.org/abs/2310.20307)\n",
    "\n",
    "**Source**: Intel Labs Causality Lab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arberzela/CircuitPFN/blob/main/notebooks/colab_cleann_causal_explanation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation\n",
    "\n",
    "First, let's install all required dependencies including the Intel Labs causality-lab library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch numpy scipy scikit-learn pandas matplotlib seaborn networkx\n",
    "!pip install tabpfn\n",
    "!pip install openml\n",
    "\n",
    "# Install Intel Labs causality-lab\n",
    "!pip install git+https://github.com/IntelLabs/causality-lab.git\n",
    "\n",
    "# Clone the CircuitPFN repository (if running in Colab)\n",
    "import os\n",
    "if not os.path.exists('CircuitPFN'):\n",
    "    !git clone https://github.com/arberzela/CircuitPFN.git\n",
    "    %cd CircuitPFN\n",
    "else:\n",
    "    print(\"Repository already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "# Import from causality-lab\n",
    "from causal_discovery_algs import LearnStructICD\n",
    "from causal_discovery_algs.icd import create_pds_tree\n",
    "from causal_discovery_utils.cond_indep_tests import CondIndepParCorr\n",
    "from causal_discovery_utils.stat_utils import cov_to_corr\n",
    "\n",
    "# Import from the CircuitPFN repository\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from attn_scm.attention import AttentionExtractor\n",
    "from utils.data_generation import generate_synthetic_dataset\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANN Implementation\n",
    "\n",
    "The CLEANN algorithm extracts causal explanations from attention patterns:\n",
    "1. Converts attention matrices to correlation matrices\n",
    "2. Learns causal graph structure using conditional independence tests\n",
    "3. Generates minimal explanation sets for target nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLEANN:\n",
    "    \"\"\"CLEANN: Causal Lens for Explaining Attention Networks\n",
    "    \n",
    "    Adapted from Intel Labs causality-lab:\n",
    "    https://github.com/IntelLabs/causality-lab/blob/main/causal_reasoning/cleann_explainer.py\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, attention_matrix: np.ndarray, num_samples: int, \n",
    "                 p_val_th: float = 0.05, explanation_tester=None, \n",
    "                 nodes_set=None, search_minimal=True, \n",
    "                 structure_learning_class=LearnStructICD):\n",
    "        \"\"\"\n",
    "        Initialize CLEANN explainer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        attention_matrix : np.ndarray\n",
    "            Attention weights matrix (n_features x n_features)\n",
    "        num_samples : int\n",
    "            Number of samples used to generate attention (for statistical tests)\n",
    "        p_val_th : float\n",
    "            P-value threshold for conditional independence tests\n",
    "        explanation_tester : callable, optional\n",
    "            Function to validate if a set is a valid explanation\n",
    "        nodes_set : set, optional\n",
    "            Set of node indices to consider (default: all nodes)\n",
    "        search_minimal : bool\n",
    "            If True, search for minimal explanation sets only\n",
    "        structure_learning_class : class\n",
    "            Structure learning algorithm class (default: ICD)\n",
    "        \"\"\"\n",
    "        # Calculate correlation matrix from attention matrix\n",
    "        cov_matrix = np.matmul(attention_matrix, attention_matrix.transpose())\n",
    "        corr_mat = cov_to_corr(cov_matrix)\n",
    "        \n",
    "        # Prepare for learning a graph\n",
    "        num_vars, _ = corr_mat.shape\n",
    "        if nodes_set is None:\n",
    "            nodes_set = set(range(num_vars))\n",
    "        self.nodes_set = nodes_set\n",
    "        \n",
    "        # Setup conditional independence test\n",
    "        self.ci_test = CondIndepParCorr(\n",
    "            threshold=p_val_th, \n",
    "            dataset=None, \n",
    "            num_records=num_samples, \n",
    "            num_vars=num_vars, \n",
    "            count_tests=True, \n",
    "            use_cache=True\n",
    "        )\n",
    "        self.ci_test.correlation_matrix = corr_mat\n",
    "        \n",
    "        self.StructureLearning = structure_learning_class\n",
    "        self.graph = None\n",
    "        \n",
    "        # Initialize for evaluating explanations\n",
    "        self.results = dict()\n",
    "        self.is_explanation = explanation_tester\n",
    "        self._search_minimal = search_minimal\n",
    "        \n",
    "        # Store correlation matrix for visualization\n",
    "        self.correlation_matrix = corr_mat\n",
    "    \n",
    "    def learn_graph(self):\n",
    "        \"\"\"Learn causal graph structure using ICD algorithm.\"\"\"\n",
    "        icd_alg = self.StructureLearning(\n",
    "            nodes_set=self.nodes_set, \n",
    "            ci_test=self.ci_test\n",
    "        )\n",
    "        icd_alg.learn_structure()\n",
    "        return icd_alg.graph\n",
    "    \n",
    "    def explain(self, target_node_idx: int, max_set_size=None, max_range=None):\n",
    "        \"\"\"\n",
    "        Identify minimal explanation set for the target node.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        target_node_idx : int\n",
    "            Index of the node to explain\n",
    "        max_set_size : int, optional\n",
    "            Maximum size of explanation sets to consider\n",
    "        max_range : int, optional\n",
    "            Maximum distance in PDS tree to search\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            List of explanation sets (tuples of node indices and depths)\n",
    "        \"\"\"\n",
    "        # Learn a Graph if one hasn't been learned already\n",
    "        if self.graph is None:\n",
    "            self.graph = self.learn_graph()\n",
    "        \n",
    "        # Create a PDS-tree rooted at the target node\n",
    "        pds_tree, full_explain_set = create_pds_tree(\n",
    "            self.graph, target_node_idx, max_depth=max_range\n",
    "        )\n",
    "        max_pds_tree_depth = pds_tree.get_max_depth()\n",
    "        \n",
    "        results = dict()\n",
    "        results['pds_tree'] = pds_tree\n",
    "        results['full_explanation_set'] = full_explain_set\n",
    "        results['max_pds_tree_depth'] = max_pds_tree_depth\n",
    "        \n",
    "        if max_set_size is None:\n",
    "            max_size = len(full_explain_set)\n",
    "        else:\n",
    "            max_size = max_set_size\n",
    "        \n",
    "        explanations_list = []\n",
    "        if self.is_explanation is None:\n",
    "            if len(full_explain_set) <= max_size:\n",
    "                explanations_list.append([full_explain_set, max_size])\n",
    "        else:\n",
    "            found_explanation = False\n",
    "            for set_size in range(1, max_size+1):\n",
    "                sets_list = pds_tree.get_subsets_list(\n",
    "                    set_nodes=full_explain_set, subset_size=set_size\n",
    "                )\n",
    "                sets_list.sort(key=lambda x: x[1])\n",
    "                for possible_explanation_set in sets_list:\n",
    "                    if self.is_explanation(list(possible_explanation_set[0]), \n",
    "                                         target_node_idx):\n",
    "                        explanations_list.append(possible_explanation_set)\n",
    "                        found_explanation = True\n",
    "                if found_explanation and self._search_minimal:\n",
    "                    break\n",
    "        \n",
    "        results['explanations'] = explanations_list\n",
    "        self.results[target_node_idx] = results\n",
    "        return explanations_list\n",
    "    \n",
    "    def get_adjacency_matrix(self):\n",
    "        \"\"\"Convert learned graph to adjacency matrix.\"\"\"\n",
    "        if self.graph is None:\n",
    "            self.graph = self.learn_graph()\n",
    "        \n",
    "        num_nodes = len(self.nodes_set)\n",
    "        adj_matrix = np.zeros((num_nodes, num_nodes))\n",
    "        \n",
    "        for node in self.graph.nodes:\n",
    "            parents = self.graph.parents[node]\n",
    "            for parent in parents:\n",
    "                adj_matrix[parent, node] = 1\n",
    "        \n",
    "        return adj_matrix\n",
    "\n",
    "print(\"✓ CLEANN class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pretrained TabPFN Classifier\n",
    "\n",
    "We'll use TabPFN to extract attention patterns that CLEANN will analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pretrained TabPFN classifier\n",
    "tabpfn_model = TabPFNClassifier(device='cpu', N_ensemble_configurations=4)\n",
    "\n",
    "print(\"✓ TabPFN model loaded successfully!\")\n",
    "print(f\"  Device: {tabpfn_model.device}\")\n",
    "print(f\"  Max samples: 1000\")\n",
    "print(f\"  Max features: 100\")\n",
    "print(\"\\nTabPFN uses pre-trained weights from meta-learning on synthetic datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Tabular Datasets\n",
    "\n",
    "We'll use three datasets to demonstrate CLEANN:\n",
    "- **Dataset 1**: Synthetic data with known causal structure (Linear-Gaussian SCM)\n",
    "- **Dataset 2**: Synthetic data with non-linear relationships\n",
    "- **Dataset 3**: Real-world dataset from OpenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: Synthetic Linear-Gaussian SCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset with known causal graph\n",
    "X1, y1, true_adj1 = generate_synthetic_dataset(\n",
    "    n_nodes=10,              # 10 features\n",
    "    n_samples=500,           # 500 samples\n",
    "    edge_prob=0.3,           # 30% edge probability\n",
    "    scm_type='linear_gaussian',  # Linear Gaussian SCM\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "feature_names1 = [f'X{i}' for i in range(10)]\n",
    "\n",
    "print(\"Dataset 1: Synthetic Linear-Gaussian SCM\")\n",
    "print(f\"  Shape: {X1.shape}\")\n",
    "print(f\"  Features: {X1.shape[1]}\")\n",
    "print(f\"  Samples: {X1.shape[0]}\")\n",
    "print(f\"  True edges: {int(true_adj1.sum())}\")\n",
    "print(f\"  Graph density: {true_adj1.sum() / (10*10):.2%}\")\n",
    "\n",
    "# Visualize ground truth\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(true_adj1, cmap='Blues', square=True, ax=ax[0],\n",
    "            xticklabels=feature_names1, yticklabels=feature_names1,\n",
    "            cbar_kws={'label': 'Edge'})\n",
    "ax[0].set_title('Ground Truth Causal Graph (Adjacency Matrix)', fontweight='bold')\n",
    "ax[0].set_xlabel('Target')\n",
    "ax[0].set_ylabel('Source')\n",
    "\n",
    "# Network graph\n",
    "G1 = nx.DiGraph(true_adj1)\n",
    "pos1 = nx.spring_layout(G1, seed=42, k=2)\n",
    "nx.draw_networkx_nodes(G1, pos1, node_color='lightblue', node_size=800, ax=ax[1])\n",
    "nx.draw_networkx_edges(G1, pos1, edge_color='gray', arrows=True, \n",
    "                       arrowsize=15, arrowstyle='->', ax=ax[1])\n",
    "nx.draw_networkx_labels(G1, pos1, {i: feature_names1[i] for i in range(10)}, \n",
    "                       font_size=10, font_weight='bold', ax=ax[1])\n",
    "ax[1].set_title('Ground Truth Causal DAG', fontweight='bold')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2: Synthetic Non-linear SCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-linear dataset\n",
    "X2, y2, true_adj2 = generate_synthetic_dataset(\n",
    "    n_nodes=8,\n",
    "    n_samples=400,\n",
    "    edge_prob=0.35,\n",
    "    scm_type='nonlinear_anm',  # Non-linear Additive Noise Model\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "feature_names2 = [f'F{i}' for i in range(8)]\n",
    "\n",
    "print(\"Dataset 2: Synthetic Non-linear SCM\")\n",
    "print(f\"  Shape: {X2.shape}\")\n",
    "print(f\"  True edges: {int(true_adj2.sum())}\")\n",
    "print(f\"  Mechanism: Polynomial + Sigmoid functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3: Real-world Dataset (OpenML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load a small real-world dataset from OpenML\n",
    "# Using diabetes dataset (37) which is small and well-known\n",
    "dataset = openml.datasets.get_dataset(37)  # Pima Indians Diabetes\n",
    "X3_full, y3_full, categorical, feature_names3 = dataset.get_data(\n",
    "    dataset_format='array',\n",
    "    target=dataset.default_target_attribute\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y3_full = le.fit_transform(y3_full)\n",
    "\n",
    "# Limit to TabPFN constraints (max 1000 samples)\n",
    "X3 = X3_full[:500]\n",
    "y3 = y3_full[:500]\n",
    "\n",
    "print(\"Dataset 3: Real-world (Pima Indians Diabetes)\")\n",
    "print(f\"  Shape: {X3.shape}\")\n",
    "print(f\"  Features: {list(feature_names3)}\")\n",
    "print(f\"  Classes: {np.unique(y3)}\")\n",
    "print(f\"  Note: Ground truth causal graph is unknown for real-world data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Attention Patterns from TabPFN\n",
    "\n",
    "First, we need to extract attention matrices from TabPFN's transformer layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize attention extractor\n",
    "attention_extractor1 = AttentionExtractor(tabpfn_model)\n",
    "\n",
    "# Fit TabPFN and extract attention patterns\n",
    "print(\"Extracting attention patterns from TabPFN...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "attention_dict1 = attention_extractor1.extract_attention(X1, y1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Attention extraction complete!\")\n",
    "print(f\"\\nExtracted attention from {len(attention_dict1)} layers\")\n",
    "print(f\"Attention shape per layer: {attention_dict1[0].shape}\")\n",
    "print(f\"  (num_heads, num_features, num_features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Attention Across Layers and Heads\n",
    "\n",
    "CLEANN works with a single attention matrix, so we'll aggregate across layers and heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_attention(attention_dict, method='mean'):\n",
    "    \"\"\"\n",
    "    Aggregate attention matrices across layers and heads.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    attention_dict : dict\n",
    "        Dictionary mapping layer indices to attention tensors\n",
    "    method : str\n",
    "        Aggregation method: 'mean', 'max', or 'sum'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Aggregated attention matrix (n_features x n_features)\n",
    "    \"\"\"\n",
    "    all_attention = []\n",
    "    \n",
    "    for layer_idx in attention_dict:\n",
    "        layer_attn = attention_dict[layer_idx]  # (heads, d, d)\n",
    "        # Average across heads\n",
    "        avg_attn = layer_attn.mean(axis=0)  # (d, d)\n",
    "        all_attention.append(avg_attn)\n",
    "    \n",
    "    # Stack all layers\n",
    "    stacked = np.stack(all_attention, axis=0)  # (layers, d, d)\n",
    "    \n",
    "    # Aggregate across layers\n",
    "    if method == 'mean':\n",
    "        aggregated = stacked.mean(axis=0)\n",
    "    elif method == 'max':\n",
    "        aggregated = stacked.max(axis=0)\n",
    "    elif method == 'sum':\n",
    "        aggregated = stacked.sum(axis=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown aggregation method: {method}\")\n",
    "    \n",
    "    return aggregated\n",
    "\n",
    "# Aggregate attention for Dataset 1\n",
    "aggregated_attention1 = aggregate_attention(attention_dict1, method='mean')\n",
    "\n",
    "print(f\"Aggregated attention matrix shape: {aggregated_attention1.shape}\")\n",
    "print(f\"Attention values range: [{aggregated_attention1.min():.4f}, {aggregated_attention1.max():.4f}]\")\n",
    "\n",
    "# Visualize aggregated attention\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(aggregated_attention1, cmap='viridis', square=True, ax=ax,\n",
    "            xticklabels=feature_names1, yticklabels=feature_names1,\n",
    "            cbar_kws={'label': 'Attention Weight'})\n",
    "ax.set_title('Aggregated Attention Matrix (Dataset 1)\\nAveraged across layers and heads', \n",
    "             fontweight='bold')\n",
    "ax.set_xlabel('To Feature')\n",
    "ax.set_ylabel('From Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply CLEANN Algorithm\n",
    "\n",
    "Now we'll apply CLEANN to learn the causal graph structure from attention patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Apply CLEANN to Dataset 1 (Linear-Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLEANN with aggregated attention\n",
    "cleann_model1 = CLEANN(\n",
    "    attention_matrix=aggregated_attention1,\n",
    "    num_samples=X1.shape[0],\n",
    "    p_val_th=0.05,  # p-value threshold for conditional independence\n",
    "    search_minimal=True\n",
    ")\n",
    "\n",
    "print(\"Applying CLEANN to Dataset 1...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Learn causal graph structure\n",
    "learned_graph1 = cleann_model1.learn_graph()\n",
    "learned_adj1 = cleann_model1.get_adjacency_matrix()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Causal graph learning complete!\")\n",
    "print(f\"\\nPredicted edges: {int(learned_adj1.sum())}\")\n",
    "print(f\"True edges: {int(true_adj1.sum())}\")\n",
    "\n",
    "# Visualize correlation matrix (intermediate step)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Original attention\n",
    "sns.heatmap(aggregated_attention1, cmap='viridis', square=True, ax=axes[0],\n",
    "            xticklabels=feature_names1, yticklabels=feature_names1,\n",
    "            cbar_kws={'label': 'Attention'})\n",
    "axes[0].set_title('Aggregated Attention Matrix', fontweight='bold')\n",
    "\n",
    "# Correlation matrix\n",
    "sns.heatmap(cleann_model1.correlation_matrix, cmap='RdBu_r', square=True, ax=axes[1],\n",
    "            xticklabels=feature_names1, yticklabels=feature_names1,\n",
    "            vmin=-1, vmax=1, center=0,\n",
    "            cbar_kws={'label': 'Correlation'})\n",
    "axes[1].set_title('Correlation Matrix\\n(Computed from Attention)', fontweight='bold')\n",
    "\n",
    "# Learned causal graph\n",
    "sns.heatmap(learned_adj1, cmap='Blues', square=True, ax=axes[2],\n",
    "            xticklabels=feature_names1, yticklabels=feature_names1,\n",
    "            cbar_kws={'label': 'Edge'})\n",
    "axes[2].set_title('Learned Causal Graph\\n(via ICD Algorithm)', fontweight='bold')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('To Feature')\n",
    "    ax.set_ylabel('From Feature')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Apply CLEANN to Dataset 2 (Non-linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention for Dataset 2\n",
    "attention_extractor2 = AttentionExtractor(tabpfn_model)\n",
    "attention_dict2 = attention_extractor2.extract_attention(X2, y2)\n",
    "aggregated_attention2 = aggregate_attention(attention_dict2, method='mean')\n",
    "\n",
    "# Apply CLEANN\n",
    "cleann_model2 = CLEANN(\n",
    "    attention_matrix=aggregated_attention2,\n",
    "    num_samples=X2.shape[0],\n",
    "    p_val_th=0.05,\n",
    "    search_minimal=True\n",
    ")\n",
    "\n",
    "print(\"Applying CLEANN to Dataset 2...\")\n",
    "learned_graph2 = cleann_model2.learn_graph()\n",
    "learned_adj2 = cleann_model2.get_adjacency_matrix()\n",
    "print(f\"✓ Complete! Predicted edges: {int(learned_adj2.sum())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Apply CLEANN to Dataset 3 (Real-world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention for Dataset 3\n",
    "attention_extractor3 = AttentionExtractor(tabpfn_model)\n",
    "attention_dict3 = attention_extractor3.extract_attention(X3, y3)\n",
    "aggregated_attention3 = aggregate_attention(attention_dict3, method='mean')\n",
    "\n",
    "# Apply CLEANN\n",
    "cleann_model3 = CLEANN(\n",
    "    attention_matrix=aggregated_attention3,\n",
    "    num_samples=X3.shape[0],\n",
    "    p_val_th=0.05,\n",
    "    search_minimal=True\n",
    ")\n",
    "\n",
    "print(\"Applying CLEANN to Dataset 3 (Diabetes)...\")\n",
    "learned_graph3 = cleann_model3.learn_graph()\n",
    "learned_adj3 = cleann_model3.get_adjacency_matrix()\n",
    "print(f\"✓ Complete! Predicted edges: {int(learned_adj3.sum())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Explanations for Target Features\n",
    "\n",
    "CLEANN can identify minimal explanation sets for specific target features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Explain Target Features in Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target features to explain\n",
    "target_features = [0, 5, 9]  # X0, X5, X9\n",
    "\n",
    "print(\"Generating explanations for target features...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for target_idx in target_features:\n",
    "    print(f\"\\nTarget: {feature_names1[target_idx]} (index {target_idx})\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get explanation set\n",
    "    explanations = cleann_model1.explain(target_idx, max_set_size=5)\n",
    "    \n",
    "    if explanations:\n",
    "        for i, (explain_set, depth) in enumerate(explanations):\n",
    "            explain_names = [feature_names1[idx] for idx in explain_set]\n",
    "            print(f\"  Explanation {i+1}:\")\n",
    "            print(f\"    Set: {explain_names}\")\n",
    "            print(f\"    Size: {len(explain_set)}\")\n",
    "            print(f\"    Max depth in PDS tree: {depth}\")\n",
    "    else:\n",
    "        print(\"  No explanation found (isolated node or root)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Explanation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize explanation for a specific target\n",
    "target_to_visualize = 5  # X5\n",
    "\n",
    "if target_to_visualize in cleann_model1.results:\n",
    "    result = cleann_model1.results[target_to_visualize]\n",
    "    full_explain_set = result['full_explanation_set']\n",
    "    \n",
    "    # Create subgraph including target and its explanation set\n",
    "    nodes_to_show = sorted([target_to_visualize] + list(full_explain_set))\n",
    "    subgraph_adj = learned_adj1[np.ix_(nodes_to_show, nodes_to_show)]\n",
    "    subgraph_names = [feature_names1[i] for i in nodes_to_show]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "    \n",
    "    G_sub = nx.DiGraph(subgraph_adj)\n",
    "    pos_sub = nx.spring_layout(G_sub, seed=42, k=2)\n",
    "    \n",
    "    # Color nodes: target in red, explanatory features in lightblue\n",
    "    node_colors = ['red' if nodes_to_show[i] == target_to_visualize \n",
    "                   else 'lightblue' for i in range(len(nodes_to_show))]\n",
    "    \n",
    "    nx.draw_networkx_nodes(G_sub, pos_sub, node_color=node_colors, \n",
    "                          node_size=1500, ax=ax)\n",
    "    nx.draw_networkx_edges(G_sub, pos_sub, edge_color='gray', \n",
    "                          arrows=True, arrowsize=20, arrowstyle='->', \n",
    "                          width=2, connectionstyle='arc3,rad=0.1', ax=ax)\n",
    "    nx.draw_networkx_labels(G_sub, pos_sub, \n",
    "                           {i: subgraph_names[i] for i in range(len(subgraph_names))},\n",
    "                           font_size=11, font_weight='bold', ax=ax)\n",
    "    \n",
    "    ax.set_title(f\"Explanation Set for '{feature_names1[target_to_visualize]}'\\n\" +\n",
    "                f\"(Red = Target, Blue = Explanatory Features)\",\n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nExplanation for {feature_names1[target_to_visualize]}:\")\n",
    "    print(f\"  Full explanation set: {[feature_names1[i] for i in full_explain_set]}\")\n",
    "    print(f\"  Set size: {len(full_explain_set)}\")\n",
    "else:\n",
    "    print(f\"No explanation generated for {feature_names1[target_to_visualize]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Explain Features in Real-world Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain all features in the diabetes dataset\n",
    "print(\"Generating explanations for Diabetes dataset features:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for target_idx in range(len(feature_names3)):\n",
    "    feature_name = feature_names3[target_idx]\n",
    "    print(f\"\\n{feature_name}:\")\n",
    "    \n",
    "    explanations = cleann_model3.explain(target_idx, max_set_size=5)\n",
    "    \n",
    "    if explanations:\n",
    "        for i, (explain_set, depth) in enumerate(explanations[:1]):  # Show first explanation\n",
    "            explain_names = [feature_names3[idx] for idx in explain_set]\n",
    "            print(f\"  Explained by: {explain_names} (size: {len(explain_set)})\")\n",
    "    else:\n",
    "        print(\"  No explanation (isolated or root node)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Learned Causal Graphs\n",
    "\n",
    "Compare the learned graphs with ground truth (where available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Dataset 1: Predicted vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predicted and true graphs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Ground Truth\n",
    "G_true = nx.DiGraph(true_adj1)\n",
    "pos_true = nx.spring_layout(G_true, seed=42, k=2, iterations=50)\n",
    "\n",
    "nx.draw_networkx_nodes(G_true, pos_true, node_color='lightgreen', \n",
    "                      node_size=1200, ax=axes[0])\n",
    "nx.draw_networkx_edges(G_true, pos_true, edge_color='darkgreen', \n",
    "                      arrows=True, arrowsize=20, arrowstyle='->', \n",
    "                      connectionstyle='arc3,rad=0.1', width=2, ax=axes[0])\n",
    "nx.draw_networkx_labels(G_true, pos_true, \n",
    "                       {i: feature_names1[i] for i in range(10)},\n",
    "                       font_size=11, font_weight='bold', ax=axes[0])\n",
    "axes[0].set_title(f'Ground Truth Causal Graph\\n({int(true_adj1.sum())} edges)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Predicted (CLEANN)\n",
    "G_pred = nx.DiGraph(learned_adj1)\n",
    "pos_pred = nx.spring_layout(G_pred, seed=42, k=2, iterations=50)\n",
    "\n",
    "nx.draw_networkx_nodes(G_pred, pos_pred, node_color='lightcoral', \n",
    "                      node_size=1200, ax=axes[1])\n",
    "nx.draw_networkx_edges(G_pred, pos_pred, edge_color='darkred', \n",
    "                      arrows=True, arrowsize=20, arrowstyle='->', \n",
    "                      connectionstyle='arc3,rad=0.1', width=2, ax=axes[1])\n",
    "nx.draw_networkx_labels(G_pred, pos_pred, \n",
    "                       {i: feature_names1[i] for i in range(10)},\n",
    "                       font_size=11, font_weight='bold', ax=axes[1])\n",
    "axes[1].set_title(f'Learned Causal Graph (CLEANN)\\n({int(learned_adj1.sum())} edges)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.suptitle('Dataset 1: Linear-Gaussian SCM', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics calculation from CircuitPFN\n",
    "from attn_scm.metrics import compute_graph_metrics\n",
    "\n",
    "# Compute evaluation metrics\n",
    "metrics1 = compute_graph_metrics(learned_adj1, true_adj1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Dataset 1 - Evaluation Metrics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Structural Hamming Distance (SHD): {metrics1['shd']}\")\n",
    "print(f\"F1 Score (directed):               {metrics1['f1_directed']:.3f}\")\n",
    "print(f\"Precision:                         {metrics1['precision']:.3f}\")\n",
    "print(f\"Recall:                            {metrics1['recall']:.3f}\")\n",
    "print(f\"True Positive Edges:               {metrics1['tp']}\")\n",
    "print(f\"False Positive Edges:              {metrics1['fp']}\")\n",
    "print(f\"False Negative Edges:              {metrics1['fn']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize metrics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of metrics\n",
    "metrics_data = [metrics1['precision'], metrics1['recall'], metrics1['f1_directed']]\n",
    "axes[0].bar(['Precision', 'Recall', 'F1 Score'], metrics_data, \n",
    "           color=['steelblue', 'coral', 'seagreen'])\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Performance Metrics', fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(metrics_data):\n",
    "    axes[0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Confusion-style visualization\n",
    "edge_data = [metrics1['tp'], metrics1['fp'], metrics1['fn']]\n",
    "axes[1].bar(['True\\nPositives', 'False\\nPositives', 'False\\nNegatives'], \n",
    "           edge_data, color=['green', 'orange', 'red'])\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Edge Prediction Breakdown', fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(edge_data):\n",
    "    axes[1].text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Dataset 2: Non-linear SCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dataset 2 graphs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Ground Truth\n",
    "G_true2 = nx.DiGraph(true_adj2)\n",
    "pos_true2 = nx.spring_layout(G_true2, seed=123, k=2)\n",
    "nx.draw(G_true2, pos_true2, with_labels=True, \n",
    "        labels={i: feature_names2[i] for i in range(8)},\n",
    "        node_color='lightgreen', node_size=1200, \n",
    "        edge_color='darkgreen', width=2, arrows=True, \n",
    "        arrowsize=20, font_weight='bold', ax=axes[0])\n",
    "axes[0].set_title(f'Ground Truth\\n({int(true_adj2.sum())} edges)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "# Predicted (CLEANN)\n",
    "G_pred2 = nx.DiGraph(learned_adj2)\n",
    "pos_pred2 = nx.spring_layout(G_pred2, seed=123, k=2)\n",
    "nx.draw(G_pred2, pos_pred2, with_labels=True,\n",
    "        labels={i: feature_names2[i] for i in range(8)},\n",
    "        node_color='lightcoral', node_size=1200,\n",
    "        edge_color='darkred', width=2, arrows=True,\n",
    "        arrowsize=20, font_weight='bold', ax=axes[1])\n",
    "axes[1].set_title(f'Learned (CLEANN)\\n({int(learned_adj2.sum())} edges)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Dataset 2: Non-linear SCM', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "metrics2 = compute_graph_metrics(learned_adj2, true_adj2)\n",
    "print(f\"\\nDataset 2 Metrics: SHD={metrics2['shd']}, F1={metrics2['f1_directed']:.3f}, \"\n",
    "      f\"Precision={metrics2['precision']:.3f}, Recall={metrics2['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Dataset 3: Real-world (Diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot real-world dataset graph\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Network graph\n",
    "G_pred3 = nx.DiGraph(learned_adj3)\n",
    "pos_pred3 = nx.spring_layout(G_pred3, seed=42, k=3, iterations=50)\n",
    "\n",
    "nx.draw_networkx_nodes(G_pred3, pos_pred3, node_color='skyblue', \n",
    "                      node_size=1500, ax=axes[0])\n",
    "nx.draw_networkx_edges(G_pred3, pos_pred3, edge_color='gray', \n",
    "                      arrows=True, arrowsize=15, arrowstyle='->', \n",
    "                      connectionstyle='arc3,rad=0.1', width=1.5, ax=axes[0])\n",
    "nx.draw_networkx_labels(G_pred3, pos_pred3, \n",
    "                       {i: feature_names3[i] for i in range(len(feature_names3))},\n",
    "                       font_size=9, font_weight='bold', ax=axes[0])\n",
    "axes[0].set_title(f'Discovered Causal Graph (CLEANN)\\n({int(learned_adj3.sum())} edges)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Adjacency heatmap\n",
    "sns.heatmap(learned_adj3, cmap='Blues', square=True, ax=axes[1],\n",
    "           xticklabels=feature_names3, yticklabels=feature_names3,\n",
    "           cbar_kws={'label': 'Edge Presence'})\n",
    "axes[1].set_title('Adjacency Matrix', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('To Feature')\n",
    "axes[1].set_ylabel('From Feature')\n",
    "\n",
    "plt.suptitle('Dataset 3: Pima Indians Diabetes (Real-world)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nGraph statistics:\")\n",
    "print(f\"  Nodes: {len(feature_names3)}\")\n",
    "print(f\"  Edges: {int(learned_adj3.sum())}\")\n",
    "print(f\"  Sparsity: {1 - learned_adj3.sum() / (len(feature_names3)**2):.2%}\")\n",
    "print(f\"  Avg in-degree: {learned_adj3.sum(axis=0).mean():.2f}\")\n",
    "print(f\"  Avg out-degree: {learned_adj3.sum(axis=1).mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conditional Independence Test Statistics\n",
    "\n",
    "CLEANN uses conditional independence tests to determine graph structure. Let's examine the test statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CI test statistics from CLEANN\n",
    "print(\"Conditional Independence Test Statistics (Dataset 1):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total CI tests performed: {cleann_model1.ci_test.count}\")\n",
    "print(f\"P-value threshold: {cleann_model1.ci_test.threshold}\")\n",
    "print(f\"Cache enabled: {cleann_model1.ci_test.use_cache}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize p-value threshold impact\n",
    "p_vals = [0.001, 0.01, 0.05, 0.1, 0.2]\n",
    "edge_counts = []\n",
    "\n",
    "print(\"\\nExploring different p-value thresholds:\")\n",
    "for p_val in p_vals:\n",
    "    cleann_temp = CLEANN(\n",
    "        attention_matrix=aggregated_attention1,\n",
    "        num_samples=X1.shape[0],\n",
    "        p_val_th=p_val,\n",
    "        search_minimal=True\n",
    "    )\n",
    "    temp_graph = cleann_temp.learn_graph()\n",
    "    temp_adj = cleann_temp.get_adjacency_matrix()\n",
    "    edge_count = int(temp_adj.sum())\n",
    "    edge_counts.append(edge_count)\n",
    "    print(f\"  p-value = {p_val:.3f} -> {edge_count} edges\")\n",
    "\n",
    "# Plot p-value sensitivity\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(p_vals, edge_counts, marker='o', linewidth=2, markersize=10, \n",
    "        color='steelblue', label='Learned edges')\n",
    "ax.axhline(y=int(true_adj1.sum()), color='green', linestyle='--', \n",
    "          linewidth=2, label='Ground truth edges')\n",
    "ax.set_xlabel('P-value Threshold', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Edges', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Impact of P-value Threshold on Graph Sparsity', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated:\n",
    "\n",
    "1. ✅ **Loaded pretrained TabPFN classifier** - A transformer-based foundation model for tabular data\n",
    "\n",
    "2. ✅ **Loaded three tabular datasets**:\n",
    "   - Synthetic Linear-Gaussian SCM with known ground truth\n",
    "   - Synthetic Non-linear SCM with complex mechanisms\n",
    "   - Real-world Diabetes dataset from OpenML\n",
    "\n",
    "3. ✅ **Extracted attention patterns** - Aggregated attention matrices from TabPFN's transformer layers\n",
    "\n",
    "4. ✅ **Applied CLEANN algorithm** - Learned causal graphs by:\n",
    "   - Converting attention to correlation matrices\n",
    "   - Using conditional independence tests (partial correlation)\n",
    "   - Learning graph structure via ICD (Iterative Conditional independence Discovery) algorithm\n",
    "\n",
    "5. ✅ **Generated minimal explanations** - Identified explanation sets for target features using PDS trees\n",
    "\n",
    "6. ✅ **Visualized learned causal graphs** - Including:\n",
    "   - Network visualizations comparing predicted vs ground truth\n",
    "   - Adjacency matrix heatmaps\n",
    "   - Evaluation metrics (SHD, F1, Precision, Recall)\n",
    "   - Explanation set subgraphs\n",
    "\n",
    "7. ✅ **Analyzed CI test statistics** - Explored impact of p-value threshold on graph sparsity\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Attention-based causal discovery**: CLEANN interprets attention patterns as causal relationships\n",
    "- **Minimal explanations**: PDS trees enable efficient search for minimal explanation sets\n",
    "- **Statistical rigor**: Conditional independence testing provides formal guarantees\n",
    "- **Real-world applicability**: Can discover plausible causal structures in real datasets\n",
    "\n",
    "### Comparison: CLEANN vs Attn-SCM\n",
    "\n",
    "| Aspect | CLEANN | Attn-SCM |\n",
    "|--------|--------|----------|\n",
    "| **Approach** | Correlation + CI tests | Direct attention aggregation |\n",
    "| **Algorithm** | ICD structure learning | Entropy-based head selection |\n",
    "| **Output** | Causal graph + explanations | Causal graph only |\n",
    "| **Statistical foundation** | Partial correlation tests | Thresholding + directionality |\n",
    "| **Interpretability** | High (minimal explanations) | Medium (attention patterns) |\n",
    "\n",
    "### References\n",
    "\n",
    "- **CLEANN**: [Accelerated Trojan Shield for Embedded Neural Networks](https://arxiv.org/abs/2310.20307)\n",
    "- **Intel Labs Causality Lab**: https://github.com/IntelLabs/causality-lab\n",
    "- **TabPFN**: Hollmann et al. (2023) - \"TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second\"\n",
    "\n",
    "---\n",
    "\n",
    "**Repository**: https://github.com/arberzela/CircuitPFN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
