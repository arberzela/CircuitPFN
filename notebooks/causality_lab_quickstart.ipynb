{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causality Lab Integration - Quick Start\n",
    "\n",
    "This notebook demonstrates how to use Intel Labs causality-lab algorithms with TabPFN on tabular data.\n",
    "\n",
    "We'll cover:\n",
    "1. Basic causal discovery with causality-lab algorithms\n",
    "2. Comparing different methods\n",
    "3. TabPFN-enhanced causal discovery\n",
    "4. Applying to real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from attn_scm.core import AttnSCM\n",
    "from attn_scm.metrics import compute_graph_metrics\n",
    "from baselines import CAUSALITY_LAB_AVAILABLE, run_rai, run_fci, run_icd\n",
    "from utils import generate_synthetic_dataset, visualize_graph\n",
    "\n",
    "print(f\"Causality Lab available: {CAUSALITY_LAB_AVAILABLE}\")\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data with Known Causal Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset with linear Gaussian SCM\n",
    "X, y, true_adj = generate_synthetic_dataset(\n",
    "    n_nodes=10,\n",
    "    n_samples=500,\n",
    "    edge_prob=0.3,\n",
    "    scm_type='linear_gaussian',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Number of true edges: {true_adj.sum()}\")\n",
    "\n",
    "# Visualize ground truth\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(true_adj, cmap='RdBu_r', center=0, square=True, \n",
    "            xticklabels=[f'X{i}' for i in range(10)],\n",
    "            yticklabels=[f'X{i}' for i in range(10)],\n",
    "            cbar_kws={'label': 'Edge'})\n",
    "plt.title('Ground Truth Causal Graph')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Source')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Causal Discovery with Different Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 AttnSCM (Attention-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AttnSCM\n",
    "model_attnscm = AttnSCM(top_k_heads=5, threshold_method='otsu', device='cpu')\n",
    "adj_attnscm = model_attnscm.fit(X, y)\n",
    "\n",
    "# Compute metrics\n",
    "metrics_attnscm = compute_graph_metrics(adj_attnscm, true_adj)\n",
    "\n",
    "print(\"AttnSCM Results:\")\n",
    "print(f\"  SHD: {metrics_attnscm['shd']}\")\n",
    "print(f\"  F1 (directed): {metrics_attnscm['f1_directed']:.3f}\")\n",
    "print(f\"  Precision: {metrics_attnscm['precision']:.3f}\")\n",
    "print(f\"  Recall: {metrics_attnscm['recall']:.3f}\")\n",
    "print(f\"  Predicted edges: {adj_attnscm.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 RAI (Recursive Autonomy Identification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CAUSALITY_LAB_AVAILABLE:\n",
    "    # Run RAI\n",
    "    feature_names = [f'X{i}' for i in range(10)]\n",
    "    adj_rai = run_rai(X, alpha=0.05, feature_names=feature_names)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics_rai = compute_graph_metrics(adj_rai, true_adj)\n",
    "    \n",
    "    print(\"RAI Results:\")\n",
    "    print(f\"  SHD: {metrics_rai['shd']}\")\n",
    "    print(f\"  F1 (directed): {metrics_rai['f1_directed']:.3f}\")\n",
    "    print(f\"  Precision: {metrics_rai['precision']:.3f}\")\n",
    "    print(f\"  Recall: {metrics_rai['recall']:.3f}\")\n",
    "    print(f\"  Predicted edges: {adj_rai.sum()}\")\n",
    "else:\n",
    "    print(\"Causality Lab not available. Skipping RAI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 FCI (Fast Causal Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CAUSALITY_LAB_AVAILABLE:\n",
    "    # Run FCI (handles latent confounders)\n",
    "    adj_fci = run_fci(X, alpha=0.05, feature_names=feature_names)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics_fci = compute_graph_metrics(adj_fci, true_adj)\n",
    "    \n",
    "    print(\"FCI Results:\")\n",
    "    print(f\"  SHD: {metrics_fci['shd']}\")\n",
    "    print(f\"  F1 (directed): {metrics_fci['f1_directed']:.3f}\")\n",
    "    print(f\"  Precision: {metrics_fci['precision']:.3f}\")\n",
    "    print(f\"  Recall: {metrics_fci['recall']:.3f}\")\n",
    "    print(f\"  Predicted edges: {adj_fci.sum()}\")\n",
    "else:\n",
    "    print(\"Causality Lab not available. Skipping FCI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ICD (Iterative Causal Discovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CAUSALITY_LAB_AVAILABLE:\n",
    "    # Run ICD\n",
    "    adj_icd = run_icd(X, alpha=0.05, feature_names=feature_names)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics_icd = compute_graph_metrics(adj_icd, true_adj)\n",
    "    \n",
    "    print(\"ICD Results:\")\n",
    "    print(f\"  SHD: {metrics_icd['shd']}\")\n",
    "    print(f\"  F1 (directed): {metrics_icd['f1_directed']:.3f}\")\n",
    "    print(f\"  Precision: {metrics_icd['precision']:.3f}\")\n",
    "    print(f\"  Recall: {metrics_icd['recall']:.3f}\")\n",
    "    print(f\"  Predicted edges: {adj_icd.sum()}\")\n",
    "else:\n",
    "    print(\"Causality Lab not available. Skipping ICD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all methods\n",
    "methods = ['Ground Truth', 'AttnSCM']\n",
    "adjacencies = [true_adj, adj_attnscm]\n",
    "\n",
    "if CAUSALITY_LAB_AVAILABLE:\n",
    "    methods.extend(['RAI', 'FCI', 'ICD'])\n",
    "    adjacencies.extend([adj_rai, adj_fci, adj_icd])\n",
    "\n",
    "fig, axes = plt.subplots(1, len(methods), figsize=(5*len(methods), 4))\n",
    "\n",
    "for ax, method, adj in zip(axes, methods, adjacencies):\n",
    "    sns.heatmap(adj, cmap='RdBu_r', center=0, square=True, ax=ax,\n",
    "                xticklabels=[f'X{i}' for i in range(10)],\n",
    "                yticklabels=[f'X{i}' for i in range(10)],\n",
    "                cbar_kws={'label': 'Edge'})\n",
    "    ax.set_title(method)\n",
    "    ax.set_xlabel('Target')\n",
    "    ax.set_ylabel('Source')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "results.append({'Method': 'AttnSCM', **metrics_attnscm})\n",
    "\n",
    "if CAUSALITY_LAB_AVAILABLE:\n",
    "    results.append({'Method': 'RAI', **metrics_rai})\n",
    "    results.append({'Method': 'FCI', **metrics_fci})\n",
    "    results.append({'Method': 'ICD', **metrics_icd})\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results[['Method', 'shd', 'f1_directed', 'precision', 'recall', \n",
    "                         'n_predicted_edges', 'n_true_edges']]\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Visualize F1 scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(df_results['Method'], df_results['f1_directed'])\n",
    "plt.ylabel('F1 Score (Directed)')\n",
    "plt.title('Causal Discovery Performance Comparison')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TabPFN-Enhanced Causal Discovery\n",
    "\n",
    "Now let's see how TabPFN's attention patterns can enhance traditional causal discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CAUSALITY_LAB_AVAILABLE:\n",
    "    from baselines.tabpfn_causality_adapter import CondIndepAttentionWeighted\n",
    "    from causality_lab.learn_structure import LearnStructRAI\n",
    "    from causality_lab.data import Dataset\n",
    "    \n",
    "    # Extract attention matrix from TabPFN\n",
    "    attention_matrix = model_attnscm.get_adjacency_matrix(binarize=False)\n",
    "    \n",
    "    # Create attention-weighted conditional independence test\n",
    "    dataset = Dataset(X, var_names=feature_names)\n",
    "    cond_indep_test = CondIndepAttentionWeighted(\n",
    "        dataset,\n",
    "        threshold=0.05,\n",
    "        attention_weights=attention_matrix\n",
    "    )\n",
    "    \n",
    "    # Run RAI with attention weighting\n",
    "    nodes_set = set(feature_names)\n",
    "    rai_learner = LearnStructRAI(nodes_set, cond_indep_test)\n",
    "    rai_learner.learn_structure()\n",
    "    \n",
    "    # Convert to adjacency\n",
    "    n_features = len(feature_names)\n",
    "    adj_rai_attention = np.zeros((n_features, n_features), dtype=int)\n",
    "    name_to_idx = {name: idx for idx, name in enumerate(feature_names)}\n",
    "    \n",
    "    for edge in rai_learner.graph.edges:\n",
    "        if hasattr(edge, 'source') and hasattr(edge, 'target'):\n",
    "            source_idx = name_to_idx.get(edge.source.name)\n",
    "            target_idx = name_to_idx.get(edge.target.name)\n",
    "            if source_idx is not None and target_idx is not None:\n",
    "                adj_rai_attention[source_idx, target_idx] = 1\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics_rai_attention = compute_graph_metrics(adj_rai_attention, true_adj)\n",
    "    \n",
    "    print(\"RAI with Attention Weighting Results:\")\n",
    "    print(f\"  SHD: {metrics_rai_attention['shd']}\")\n",
    "    print(f\"  F1 (directed): {metrics_rai_attention['f1_directed']:.3f}\")\n",
    "    print(f\"  Precision: {metrics_rai_attention['precision']:.3f}\")\n",
    "    print(f\"  Recall: {metrics_rai_attention['recall']:.3f}\")\n",
    "    \n",
    "    # Compare with standard RAI\n",
    "    improvement = metrics_rai_attention['f1_directed'] - metrics_rai['f1_directed']\n",
    "    print(f\"\\nImprovement over standard RAI: {improvement:+.3f}\")\n",
    "else:\n",
    "    print(\"Causality Lab not available. Skipping TabPFN-enhanced discovery.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real-World Dataset Example\n",
    "\n",
    "Let's apply these methods to a real-world dataset from OpenML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load diabetes dataset\n",
    "dataset = openml.datasets.get_dataset(37)  # Pima Indians Diabetes\n",
    "X_real, y_real, categorical, feature_names_real = dataset.get_data(\n",
    "    dataset_format='array',\n",
    "    target=dataset.default_target_attribute\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_real = le.fit_transform(y_real)\n",
    "\n",
    "# Limit to TabPFN constraints\n",
    "X_real = X_real[:500]\n",
    "y_real = y_real[:500]\n",
    "\n",
    "print(f\"Dataset shape: {X_real.shape}\")\n",
    "print(f\"Features: {list(feature_names_real)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AttnSCM on real data\n",
    "model_real = AttnSCM(top_k_heads=5, threshold_method='otsu', device='cpu')\n",
    "adj_real_attnscm = model_real.fit(X_real, y_real)\n",
    "\n",
    "print(f\"Discovered edges: {adj_real_attnscm.sum()}\")\n",
    "print(f\"Graph sparsity: {1 - adj_real_attnscm.sum() / (X_real.shape[1]**2):.3f}\")\n",
    "\n",
    "# Visualize discovered graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(adj_real_attnscm, cmap='RdBu_r', center=0, square=True,\n",
    "            xticklabels=feature_names_real,\n",
    "            yticklabels=feature_names_real,\n",
    "            cbar_kws={'label': 'Edge'})\n",
    "plt.title('Discovered Causal Graph: Diabetes Dataset (AttnSCM)')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Source')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CAUSALITY_LAB_AVAILABLE:\n",
    "    # Compare with RAI\n",
    "    adj_real_rai = run_rai(X_real, alpha=0.05, feature_names=list(feature_names_real))\n",
    "    \n",
    "    print(f\"\\nRAI discovered edges: {adj_real_rai.sum()}\")\n",
    "    \n",
    "    # Compare edge overlap\n",
    "    common_edges = np.sum((adj_real_attnscm == 1) & (adj_real_rai == 1))\n",
    "    print(f\"Common edges between AttnSCM and RAI: {common_edges}\")\n",
    "    print(f\"Edge agreement: {np.mean(adj_real_attnscm == adj_real_rai):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Multiple causal discovery methods**: AttnSCM, RAI, FCI, ICD\n",
    "2. **Performance comparison** on synthetic data with known ground truth\n",
    "3. **TabPFN-enhanced discovery** using attention-weighted conditional independence tests\n",
    "4. **Real-world application** to OpenML datasets\n",
    "\n",
    "Key takeaways:\n",
    "- Different methods have different assumptions and strengths\n",
    "- TabPFN's attention patterns can enhance traditional causal discovery\n",
    "- Real-world causal discovery requires validation through domain knowledge or predictive utility\n",
    "\n",
    "For more examples, see:\n",
    "- `experiments/exp_a_causality_lab.py` - Full synthetic benchmark\n",
    "- `experiments/exp_e_tabpfn_enhanced_causality.py` - TabPFN enhancement experiments\n",
    "- `experiments/exp_f_real_datasets.py` - Real-world dataset evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
